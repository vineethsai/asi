---
id: "AVD-2024-003"
title: "Hugging Face Model Repository Supply Chain Attack"
description: "Malicious actors created fake organization accounts on Hugging Face impersonating real companies, leading to employees uploading sensitive models to attacker-controlled repositories."
severity: "critical"
cvss_score: 9.1
cve_id: null
disclosure_date: "2024-06-19"
discovered_by: "threffall_hax"
affected_systems:
  - "Hugging Face Model Hub"
  - "Corporate AI Development Workflows"
  - "Model Deployment Pipelines"
vulnerability_type: "supply_chain_attack"
attack_vector: "social_engineering"
impact:
  confidentiality: true
  integrity: true
  availability: true
technical_details:
  attack_method: "Creation of legitimate-looking organization accounts to trick employees into joining and uploading proprietary models"
  exploitation_complexity: "low"
  user_interaction: "required"
  scope: "changed"
threat_mapping:
  - "t13"
  - "t1"
mitigation_mapping:
  - "m16"
  - "m14"
  - "m6"
proof_of_concept:
  available: true
  description: "Demonstrated ability to embed malware in AI models and gain access to victim environments"
remediation:
  vendor_response: "Hugging Face improved organization verification processes"
  workarounds:
    - "Verify organization authenticity before joining"
    - "Use private repositories for sensitive models"
    - "Implement model scanning before deployment"
  patch_status: "mitigated"
references:
  - title: "Hugging Face Supply Chain Attack Research"
    url: "https://5stars217.github.io/"
    type: "research_blog"
tags:
  - "supply_chain"
  - "social_engineering"
  - "model_theft"
  - "impersonation"
status: "disclosed"
last_updated: "2024-06-20"
---

# Hugging Face Model Repository Supply Chain Attack

## Overview

This critical vulnerability demonstrates a sophisticated supply chain attack targeting AI development workflows through Hugging Face's model repository platform. Attackers created convincing fake organization accounts impersonating legitimate companies to trick employees into uploading proprietary AI models to attacker-controlled repositories.

## Technical Details

The attack methodology involves:

1. **Organization Impersonation**: Creating fake Hugging Face organization accounts with names similar to legitimate companies
2. **Social Engineering**: Inviting company employees to join the fake organizations
3. **Model Harvesting**: Collecting proprietary models uploaded by unsuspecting employees
4. **Malware Injection**: Embedding malicious code within seemingly legitimate models

## Attack Flow

```
1. Attacker creates fake "CompanyAI" organization on Hugging Face
2. Attacker invites real CompanyAI employees to join
3. Employees upload sensitive/proprietary models
4. Attacker gains access to intellectual property
5. Attacker can inject malware into models for downstream attacks
```

## Impact

This vulnerability has severe implications:

- **Intellectual Property Theft**: Proprietary AI models and training data exposed
- **Supply Chain Compromise**: Malicious models distributed to downstream users
- **Corporate Espionage**: Access to sensitive business logic and data
- **Malware Distribution**: Infected models can compromise deployment environments

## Real-World Consequences

The research demonstrated:
- Successful impersonation of major tech companies
- Ability to embed persistent malware in AI models
- Potential for large-scale supply chain attacks
- Difficulty in detecting malicious models

## Mitigation Strategies

Organizations should implement:

1. **Verification Processes**: Always verify organization authenticity before joining
2. **Private Repositories**: Use private repos for sensitive models
3. **Model Scanning**: Implement automated scanning for malicious content
4. **Access Controls**: Strict permissions for model uploads and sharing
5. **Employee Training**: Educate staff about social engineering tactics 